\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Conversational Agent Debating Capability}

\author{
\IEEEauthorblockN{Mohamad Faraj Makkawi}
\IEEEauthorblockA{\textit{IMT Atlantique} \\ Rennes, France \\ mohamad.makkawi@imt-atlantique.net}
\and
\IEEEauthorblockN{Hassan Khan}
\IEEEauthorblockA{\textit{IMT Atlantique} \\ Rennes, France \\ hassan.khan@imt-atlantique.net}
}

\maketitle

\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}
AI, Debate Systems, Argumentation, Conversational Agents, Argumentation Service Platform with Integrated Components (ASPIC).
\end{IEEEkeywords}

\section{Introduction}
The application of symbolic AI methods holds significant promise for developing transparent and trustworthy debate systems. This paper discusses how methods like ASPIC and defeasible logic programming apply knowledge structure representation and reasoning to enable conversational agents to construct and present sound arguments transparently. We emphasize the explainability of the reasoning and ability to manipulate abstractions, strengths of symbolic techniques \cite{b8}. We will mention the knowledge shortcomings, such as uncertainty and handling large data sets, bottlenecks in knowledge acquisition, and dynamic evaluation difficulties in real-time \cite{b9}. By reviewing existing conversational agent architectures, this paper will try to get a glimpse into the potential and boundary of symbolic AI for debating conversational agents.

\section{Debate Definition and What Makes a Good Debate}
A debate is a structured conversation through the presentation of arguments by opposing sides with a view to expressing their positions, and justifications, and enabling the scrutiny of different perspectives \cite{b1}\cite{b2}. It can also be viewed as an argumentative game where the interactions are governed by predefined rules, and players engage in structured moves \cite{b6}. A good debate consists of empirical evidence-based arguments that are well-supported, clear explanations that spell out reasoning using simple language, and an awareness of counterarguments to back persuasive attempts. Moreover, logical coherence between premises and the categorization of argument quality are elements that make the responses effective as a whole \cite{b6}.

\section{Conversational Agent Debating Techniques and Applications}
\begin{itemize}
    \item \textbf{Argument graphs:} Argument graphs are graph representations employed to illustrate arguments and their interrelations. Under this paradigm of thinking, nodes are indicative of independent arguments, whereas the edges linking them are instances of relations among such arguments. Argument graphs enable agents to visualize the composition of arguments and their relations to one another, thereby determining appropriate contexts for the application of specific arguments \cite{b4}\cite{b6}.
    \item \textbf{ASPIC framework:} ASPIC is a formal framework for constructing and analyzing arguments, with premises reflecting the fact domain over which the argument is being constructed, and inference rules under which conclusions are drawn from premises. Preference rules are then used to prefer some arguments over others, on both logical grounds as well as user-specific priorities \cite{b6}.
    \item \textbf{Defeasible logic programming:} Defeasible logic programming provides a setting for argumentation in the presence of exceptions and uncertainty. It is suited for the construction and evaluation of arguments in dynamic scenarios, in which conclusions drawn earlier may be superseded by information that comes later. The method seems to begin with general rules which hold by default and then have other more specific rules introduced which act to modify or supplant such defaults as information becomes available, allowing for compact and flexible argumentation \cite{b6}.
    \item \textbf{Multi-Attribute Argumentation Framework:} The Multi-Attribute Argumentation Framework is concerned with assessment of arguments on various criteria such as cost, environmental impact, and feasibility. Each attribute is given a weight depending on its significance. Arguments are then compared by contrasting their scores on these various attributes, thus giving a formal methodology for decision-making and argument evaluation \cite{b6}.
    \item \textbf{Reactive Component-Based Argumentation:} Reactive Component-Based Argumentation consists of a system with an argumentation model, a planning subsystem, and a reactive component. The planning subsystem generates a plan that gives evidence in support of persuasive goals. The reactive component, however, implements the plan through the translation of plan operators into dialogue expressions, thereby enabling it to react dynamically to the arguments of the user \cite{b7}.
    \item \textbf{Hierarchical Argumentation:} A method of organizing arguments in a tiered structured manner, where the main claim or conclusion is supported by a group of sub-arguments or evidence. It is one of the common strategies used to facilitate convincing conversations and makes it simpler for the audience to follow and establish whether the arguments are valid or not  \cite{b5}.
\end{itemize}

\section{Existing Types of Conversational Agents Capable of Debating a Subject}
Several types of conversational agents are capable of participating in debates:

\begin{itemize}
    \item \textbf{Rule-Based Agents:} Use predefined argument templates.
    \item \textbf{Retrieval-Based Agents:} Fetch arguments from a database \cite{b3}.
    \item \textbf{Hybrid Argumentation Agents:} Combine retrieval with reasoning.
    \item \textbf{Hierarchical Persuasion Agents:} Adapt arguments based on user feedback \cite{b5}.
    \item \textbf{Explainable Debate Agents:} Justify their reasoning using argumentation.
\end{itemize}


\section{The Power of Symbolic Methods in Conversational Agents}
Symbolic methods, emphasize knowledge representation in the form of structured, human-readable symbols employing logical reasoning for problem-solving. These methods rely on formal logic, rule-based systems, and knowledge graphs. The applicability of this approach is due to:

\begin{itemize}
    \item \textbf{The decision-making processes transparency:} The representation of knowledge achieved through the encoding of formal rules of debate and argumentative structures via logic-based frameworks permits artificial intelligence systems to systematically assess premises and deduce conclusions. symbolic methods captures human reasoning and guarantees transparency in decision-making \cite{b8}.
    \item \textbf{Explainable reasoning:} A very important feature in situations where an explanation is needed to support an argument and to explain the reasons for a decision. This enhances the user's confidence in the system and makes it user-friendly \cite{b9}.
    \item \textbf{Ability to work with abstract concepts and logical relationships:} Abstract notions such as mental health and social interaction can be framed in rational hierarchies and structured relations within symbolic systems. These systems enable the capacity of artificial intelligence to discuss philosophical or ethical issues using predefined logical relations and concepts \cite{b8}.
\end{itemize}

\section{Limitations of Conversational Debating Agents}
\begin{itemize}
    \item \textbf{Uncertainty and Big Data Management:} AI Debate Systems may need to handle vast amounts of data from multiple sources, often containing noisy or inconsistent information \cite{b10}.
    
    \item \textbf{Knowledge Acquisition Bottleneck:} Symbolic AI programs typically require hand-coded rules and knowledge, leading to high human effort and cost in translating real-world problems into system inputs \cite{b10}.
    
    \item \textbf{Real-time Dynamic Assessments:} AI debate systems face challenges in reacting dynamically to emerging arguments or rapidly changing contexts in real-time scenarios \cite{b10}.
    
    \item \textbf{Logical Inconsistencies:} Internal logical inconsistencies present a major hurdle in designing secure AI systems, such as debate frameworks. This issue highlights the need to integrate constrained logical verification or consistency inference tools into the AI architecture \cite{b9}.
\end{itemize}



\section{Conclusion}

\section*{Acknowledgment}
We would like to thank John Puentes and Mihai Andries, Christophe Lohr for their invaluable supervision and guidance throughout this research.

\begin{thebibliography}{00}
\bibitem{b1} Rakshit, Geetanjali, Kevin K. Bowden, Lena Reed, Amita Misra, and Marilyn Walker. "Debbie, the debate bot of the future." In \textit{Advanced Social Interaction with Agents: 8th International Workshop on Spoken Dialog Systems}, pp. 45-52. Springer International Publishing, 2019.
\bibitem{b2} Tan, Chenhao, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, and Lillian Lee. "Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions." In \textit{Proceedings of the 25th International Conference on World Wide Web}, pp. 613-624, 2016.
\bibitem{b3} Kulatska, Iryna. "ArgueBot: Enabling debates through a hybrid retrieval-generation-based chatbot." Master's thesis, University of Twente, 2019.
\bibitem{b4} Chalaguine, Lisa A., and Anthony Hunter. "A persuasive chatbot using a crowdsourced argument graph and concerns." \textit{Computational Models of Argument} 326 (2020): 9.
\bibitem{b5} Sakai, Kazuki, Ryuichiro Higashinaka, Yuichiro Yoshikawa, Hiroshi Ishiguro, and Junji Tomita. "Hierarchical argumentation structure for persuasive argumentative dialogue generation." \textit{IEICE TRANSACTIONS on Information and Systems} 103, no. 2 (2020): 424-434.
\bibitem{b6} Engelmann, Débora, Juliana Damasio, Alison R. Panisson, Viviana Mascardi, and Rafael H. Bordini. "Argumentation as a method for explainable AI: A systematic literature review." In \textit{17th IEEE Iberian Conference on Information Systems and Technologies (CISTI)}, 2022, pp. 1-6.
\bibitem{b7} Andrews, Pierre, Suresh Manandhar, and Marco De Boni. "Argumentative Human Computer Dialogue for Automated Persuasion." In \textit{Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue}, pp. 138-147, Columbus, Ohio, Jun. 2008. Association for Computational Linguistics. Available: https://aclanthology.org/W08-0123/.
\bibitem{b8} Vassiliades, A., Bassiliades, N., and Patkos, T. "Argumentation and explainable artificial intelligence: A survey," \textit{Knowledge Engineering Review}, vol. 36, e5, 1-35, 2021. doi:10.1017/S0269888921000011. [Online]. Available: https://doi.org/10.1017/S0269888921000011. [Accessed: Mar. 23, 2025].
\bibitem{b9} Ilkou, E., and Koutraki, M. "Symbolic vs Sub-symbolic AI Methods: Friends or Enemies?" In \textit{Proceedings of the CIKM 2020 Workshops}, CEUR Workshop Proceedings, ISSN 1613-0073, October 19-20, 2020, Galway, Ireland. [Online]. Available: http://ceur-ws.org. [Accessed: Mar. 23, 2025].
\bibitem{b10} Kasif, Simon. "A Trilogy of AI Safety Frameworks: Paths from Facts and Knowledge Gaps to Reliable Predictions and New Knowledge." \textit{Department of Biomedical Engineering, Program in Bioinformatics, Department of Computer Science, Boston University}.
\end{thebibliography}
\end{document}